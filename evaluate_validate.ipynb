{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Evaluation and Validation of Balanced Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Data Preparation**\n",
    "- Load the **merged balanced dataset** and **testing set**.\n",
    "- Split the **balanced dataset** into **training (X_train, y_train)**.\n",
    "- Ensure both **training and testing data** are properly **scaled**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete!\n",
      "Training set: (252000, 39)\n",
      "Validation set: (108000, 39)\n",
      "Testing set: (82332, 39)\n"
     ]
    }
   ],
   "source": [
    "# Load merged balanced dataset\n",
    "df_balanced = pd.read_csv('balanced_attack_data.csv')\n",
    "df_test = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# Drop unnecessary columns in df_test to match df_balanced\n",
    "df_test = df_test.drop(columns=[\"id\", \"proto\", \"service\", \"state\", \"label\"], errors=\"ignore\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df_balanced.drop(columns=[\"attack_cat\"])  # Features\n",
    "y = df_balanced[\"attack_cat\"]  # Labels\n",
    "\n",
    "# Split into train (70%) and validation (30%) sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Ensure test set is prepared correctly\n",
    "X_test = df_test.drop(columns=[\"attack_cat\"])\n",
    "y_test = df_test[\"attack_cat\"]\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Data preparation complete!\")\n",
    "print(f\"Training set: {X_train.shape}\\nValidation set: {X_val.shape}\\nTesting set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2: Train Machine Learning Models**\n",
    "- Choose models for evaluation:\n",
    "  - **XGBoost**\n",
    "  - **Random Forest** (Baseline)\n",
    "  - **Neural Networks (MLPClassifier)**\n",
    "- Train each model using the **balanced dataset**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation Accuracy: 0.38\n",
      "\n",
      "XGBoost Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.17      0.19      0.18     12000\n",
      "      Backdoor       0.16      0.18      0.17     12000\n",
      "           DoS       0.25      0.03      0.06     12000\n",
      "      Exploits       0.62      0.78      0.69     12000\n",
      "       Fuzzers       0.88      0.40      0.55     12000\n",
      "       Generic       1.00      0.98      0.99     12000\n",
      "Reconnaissance       0.61      0.21      0.31     12000\n",
      "     Shellcode       0.17      0.24      0.20     12000\n",
      "         Worms       0.16      0.35      0.22     12000\n",
      "\n",
      "      accuracy                           0.38    108000\n",
      "     macro avg       0.45      0.38      0.38    108000\n",
      "  weighted avg       0.45      0.38      0.38    108000\n",
      "\n",
      "\n",
      "XGBoost Confusion Matrix:\n",
      " [[ 2264  2084   180   452    70     0   246  2656  4048]\n",
      " [ 2074  2172   184   448    57     1   252  2741  4071]\n",
      " [ 1520  1515   410  3310    93     4   211  1969  2968]\n",
      " [  369   376   230  9391   161    17   214   489   753]\n",
      " [ 1182  1191   118   563  4848     5   142  1571  2380]\n",
      " [    0     0    22   160    21 11788     2     6     1]\n",
      " [ 1609  1712   170   751    66     0  2539  2018  3135]\n",
      " [ 2085  2201   158    92   110     4   295  2920  4135]\n",
      " [ 2142  2309   162    20    73     0   257  2820  4217]]\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(X_train, y_train_enc)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = xgb_model.predict(X_val)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy = accuracy_score(y_val_enc, y_val_pred)\n",
    "print(f'XGBoost Validation Accuracy: {accuracy:.2f}')\n",
    "print(f'\\nXGBoost Classification Report:\\n', classification_report(y_val_enc, y_val_pred, target_names=le.classes_))\n",
    "print('\\nXGBoost Confusion Matrix:\\n', confusion_matrix(y_val_enc, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.38\n",
      "\n",
      "Random Forest Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.16      0.19      0.18     12000\n",
      "      Backdoor       0.17      0.19      0.18     12000\n",
      "           DoS       0.18      0.13      0.15     12000\n",
      "      Exploits       0.63      0.72      0.67     12000\n",
      "       Fuzzers       0.61      0.43      0.51     12000\n",
      "       Generic       1.00      0.98      0.99     12000\n",
      "Reconnaissance       0.33      0.26      0.29     12000\n",
      "     Shellcode       0.17      0.20      0.18     12000\n",
      "         Worms       0.16      0.20      0.18     12000\n",
      "\n",
      "      accuracy                           0.37    108000\n",
      "     macro avg       0.38      0.37      0.37    108000\n",
      "  weighted avg       0.38      0.37      0.37    108000\n",
      "\n",
      "\n",
      "Random Forest Confusion Matrix:\n",
      " [[ 2312  2220  1065   382   544     0  1130  2118  2229]\n",
      " [ 2274  2285  1069   360   521     1  1094  2149  2247]\n",
      " [ 1626  1589  1537  2805   422     5   787  1590  1639]\n",
      " [  420   387  1166  8613   198    13   384   375   444]\n",
      " [ 1307  1207   692   458  5153     5   619  1280  1279]\n",
      " [    0     0    48   146    12 11786     2     5     1]\n",
      " [ 1729  1654   898   688   408     0  3137  1740  1746]\n",
      " [ 2285  2202   936   121   592     4  1154  2386  2320]\n",
      " [ 2292  2282   992    89   546     0  1182  2277  2340]]\n"
     ]
    }
   ],
   "source": [
    "# Train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train_enc)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_rf = rf_model.predict(X_val)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_val_enc, y_val_pred_rf)\n",
    "print(f'Random Forest Validation Accuracy: {accuracy:.2f}')\n",
    "print(f'\\nRandom Forest Classification Report:\\n', classification_report(y_val_enc, y_val_pred_rf, target_names=le.classes_))\n",
    "print('\\nRandom Forest Confusion Matrix:\\n', confusion_matrix(y_val_enc, y_val_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier Validation Accuracy: 0.38\n",
      "\n",
      "MLPClassifier Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "      Analysis       0.79      0.01      0.01     12000\n",
      "      Backdoor       0.00      0.00      0.00     12000\n",
      "           DoS       0.00      0.00      0.00     12000\n",
      "      Exploits       0.51      0.74      0.60     12000\n",
      "       Fuzzers       0.82      0.25      0.38     12000\n",
      "       Generic       0.97      0.96      0.96     12000\n",
      "Reconnaissance       0.38      0.09      0.15     12000\n",
      "     Shellcode       0.15      0.09      0.11     12000\n",
      "         Worms       0.17      0.90      0.28     12000\n",
      "\n",
      "      accuracy                           0.34    108000\n",
      "     macro avg       0.42      0.34      0.28    108000\n",
      "  weighted avg       0.42      0.34      0.28    108000\n",
      "\n",
      "\n",
      "MLPClassifier Confusion Matrix:\n",
      " [[   64     1     0   464    45    10    38  1080 10298]\n",
      " [    0     0     0   438     6    14    71  1086 10385]\n",
      " [    3     0     0  3102    52    79   438   788  7538]\n",
      " [    3     0     0  8863   323   118   701   194  1798]\n",
      " [    9     0     0  1997  2984   140   319   645  5906]\n",
      " [    0     0     0   443    16 11480    61     0     0]\n",
      " [    0     0     0  1887   178    21  1079   835  8000]\n",
      " [    0     1     0   181    22     0   161  1060 10575]\n",
      " [    2     0     0    34     0     0     1  1155 10808]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rajasa\\miniconda3\\envs\\env_dl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Rajasa\\miniconda3\\envs\\env_dl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Rajasa\\miniconda3\\envs\\env_dl\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train the MLPClassifier model\n",
    "mlp_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "mlp_model.fit(X_train, y_train_enc)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_mlp = mlp_model.predict(X_val)\n",
    "\n",
    "# Evaluate the MLPClassifier model\n",
    "mlp_accuracy = accuracy_score(y_val_enc, y_val_pred_mlp)\n",
    "print(f'MLPClassifier Validation Accuracy: {accuracy:.2f}')\n",
    "print(f'\\nMLPClassifier Classification Report:\\n', classification_report(y_val_enc, y_val_pred_mlp, target_names=le.classes_))\n",
    "print('\\nMLPClassifier Confusion Matrix:\\n', confusion_matrix(y_val_enc, y_val_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3: Evaluate Model Performance**\n",
    "- Use the **testing set** to evaluate trained models.\n",
    "- Compute performance metrics:\n",
    "  - **Accuracy**\n",
    "  - **Precision, Recall, F1-score**\n",
    "  - **Confusion Matrix**\n",
    "  - **AUC-ROC Curve**\n",
    "- Compare results to assess improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4: Model Validation**\n",
    "- Perform **Cross-validation** on the training set.\n",
    "- Conduct **Hyperparameter tuning** (GridSearchCV, RandomizedSearchCV).\n",
    "- Check for **overfitting/underfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5: Conclusion**\n",
    "- Summarize model performances.\n",
    "- Identify the best-performing model for **network intrusion detection**.\n",
    "- Discuss whether **balancing improved model performance**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
