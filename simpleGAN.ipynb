{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the simple GAN (Generative Adversarial Network) in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "# Data Handling & Preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# Visualization & Debugging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "The dataset I'm using is UNSW-NB15, the data already split so I don't need to split it manually. The dataset is divided into:\n",
    "1. Training-set with CSV format.\n",
    "2. Testing-set with CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files\n",
    "df_train = pd.read_csv('UNSW_NB15_training-set.csv')\n",
    "df_test = pd.read_csv('UNSW_NB15_testing-set.csv')\n",
    "\n",
    "# Display the first 5 rows\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check class distribution and answer this question:\n",
    "1. What are the minority attack classes?\n",
    "2. How severe is the imbalance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check column names\n",
    "print(df_train.columns)\n",
    "\n",
    "# Count occurences of each unieque value in the attack_cat column\n",
    "print(df_train[\"attack_cat\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'attack_cat' is 'Normal'\n",
    "df_train_attack = df_train[df_train['attack_cat'] != 'Normal']\n",
    "\n",
    "# Count occurences of each attack classes\n",
    "print(df_train_attack[\"attack_cat\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df_train_attack['attack_cat'], order=df_train_attack['attack_cat'].value_counts().index)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Class Distribution of Attack Samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure how severe the imbalance is, I'm use imbalance ratio (IR) and other statistical metrics.\n",
    "The imbalance ratio (IR) tells us how imbalanced the dataset is. It’s calculated as:\n",
    "\n",
    "IR = Majority class count / Minority class count\n",
    "\n",
    "If IR > 1.5, the dataset is imbalanced.  \n",
    "If IR > 10, the imbalance is severe.  \n",
    "If any class has less than 5% of the dataset, which indicates a significant imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the majority and minority class sizes\n",
    "class_counts = df_train_attack['attack_cat'].value_counts()\n",
    "majority_class = class_counts.max()\n",
    "minority_class = class_counts.min()\n",
    "\n",
    "# Compute imbalance ratio\n",
    "imbalance_ratio = majority_class / minority_class\n",
    "print(f\"Imbalance Ratio (IR): {imbalance_ratio:.2f}\\n\")\n",
    "\n",
    "# Compute percentage distribution\n",
    "total_samples = len(df_train_attack)\n",
    "percentages = (class_counts / total_samples) * 100\n",
    "print(percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer above question is:\n",
    "1. There is few minority attack classes **less then 5%** of the dataset here: Worms, Shellcode, Backdoor, and Analysis.\n",
    "2. The Imbalance Ratio is 307.69 which indicate the dataset is **highly imbalance!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Minority Classes  \n",
    "I'm focus on attack types below **5%** (Analysis, Backdoor, Shellcode, Worms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the minority classes\n",
    "minority_classes = ['Analysis', 'Backdoor', 'Shellcode', 'Worms']\n",
    "\n",
    "# Extract samples of minority classes\n",
    "minority_df = df_train_attack[df_train_attack['attack_cat'].isin(minority_classes)]\n",
    "print(minority_df['attack_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize Features  \n",
    "GANs work best when features are scaled between **0 and 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns first\n",
    "df_train_attack.drop(columns=['id', 'label', 'service', 'state', 'proto'], inplace=True)\n",
    "\n",
    "# Select only numerical features\n",
    "numerical_cols = df_train_attack.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "# Apply MinMaxScalar to normalize the numerical features\n",
    "scaler = MinMaxScaler()\n",
    "df_train_attack[numerical_cols] = scaler.fit_transform(df_train_attack[numerical_cols])\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(f\"Selected numerical columns: {numerical_cols}\")  # Debugging step\n",
    "df_train_attack.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the GAN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN Architecture Overview  \n",
    "A GAN consist of two networks:\n",
    "1. **Generator (G)** --> Takes random noise and generates fake attack samples.\n",
    "2. **Discriminator (D)** --> Determine if a sample is real or fake."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Generator  \n",
    "The generator takes **random noise** as input and outputs a synthetic attack sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128), # Fully connected layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim), # Output the same number of features as the dataset\n",
    "            nn.Tanh() # Output values between -1 and 1\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        return self.model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input_dim** --> Size of the random noise (e.g., 100).  \n",
    "**output_dim** --> Number of features in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the Discriminator  \n",
    "The discriminator classifies data as **real (1)** or **fake (0)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.LeakyReLU(0.2), \n",
    "            nn.Linear(128, 1), \n",
    "            nn.Sigmoid() # Output probability of being real\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses **LeakyReLU** to avoid dead neurons.  \n",
    "Ends with **Sigmoid** to output probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Models & Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define dimensions\n",
    "input_dim = 100 # Random noise size\n",
    "output_dim = len(numerical_cols) # Number of features in dataset\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(input_dim, output_dim)\n",
    "discriminator = Discriminator(output_dim)\n",
    "\n",
    "# Optimizers & Loss Functions\n",
    "lr = 0.0002 # Learning rate\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss() # Binary Cross-Entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**criterion** helps measure how well the discriminator differentiates real vs. fake.  \n",
    "**Adam optimizer** helps in faster convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Process:**\n",
    "1. The **generator** tries to fool the discriminator.\n",
    "2. The **discriminator** improves by correctly classifying real vs. fake samples.\n",
    "3. Over time, the generator creates more realistic attack samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 10000 # Set the number of epochs for training\n",
    "batch_size = 64 # Set the batch size for each iteration\n",
    "\n",
    "# Loop through each minority attack class and train a separate GAN for each\n",
    "for attack_class in minority_classes:\n",
    "    print(f\"Training GAN for {attack_class}...\")\n",
    "\n",
    "    # Extract only sampls of this attack class\n",
    "    real_data_class = df_train_attack[df_train_attack['attack_cat'] == attack_class][numerical_cols].values\n",
    "    real_data_class = torch.tensor(real_data_class, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Initialize a new generator and discriminator for this class\n",
    "    generator = Generator(input_dim, output_dim).to(device)\n",
    "    discriminator = Discriminator(output_dim).to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_G = optim.Adam(generator.parameters(), lr=lr)\n",
    "    optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    # Train the GAN for this specific attack class\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle data at the start of each epoch\n",
    "        real_data_class = real_data_class[torch.randperm(real_data_class.size(0))]\n",
    "\n",
    "        # Train the GAN in mini-batches (batch_size)\n",
    "        for i in range(0, len(real_data_class), batch_size):\n",
    "            # Define batch_data as a slice of real_data_class\n",
    "            batch_data = real_data_class[i:i+batch_size].to(device)\n",
    "\n",
    "            ### Step 1: Train Discriminator ###\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Real samples\n",
    "            real_labels = torch.ones(batch_data.shape[0], 1).to(device) # Real data labels = 1\n",
    "            real_output = discriminator(batch_data)\n",
    "            loss_real = criterion(real_output, real_labels)\n",
    "\n",
    "            # Fake samples\n",
    "            noise = torch.randn(batch_data.shape[0], input_dim).to(device) # Generate random noise\n",
    "            fake_data = generator(noise) # Generate fake attack samples\n",
    "            fake_labels = torch.zeros(batch_data.shape[0], 1).to(device) # Fake data labels = 0\n",
    "            fake_output = discriminator(fake_data.detach()) # Detach to avoid generator update\n",
    "            loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "            # Total Discriminator loss\n",
    "            loss_D = loss_real + loss_fake\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            ### Step 2: Train Generator ###\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Want to fool the discriminator\n",
    "            fake_output = discriminator(fake_data)\n",
    "            loss_G = criterion(fake_output, torch.ones(batch_data.shape[0], 1).to(device)) # Fake labels = 1 (to fool D)\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] done for {attack_class}\")\n",
    "\n",
    "    print(f\"{attack_class} GAN training Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1**: Train the **discriminator** on real and fake data.  \n",
    "**Step 2**: Train the **generator** to fool the discriminator.  \n",
    "Runs for **10,000 epochs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Attack Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate New Attack Samples  \n",
    "After training, use the generator to create synthetic attack data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the size of the majority class\n",
    "majority_class_size = df_train_attack['attack_cat'].value_counts().max()\n",
    "\n",
    "# Loop through each minority attack class and generate synthetic samples\n",
    "synthetic_dataframes = []\n",
    "\n",
    "for attack_class in minority_classes:\n",
    "    print(f\"Generating synthetic samples for {attack_class}...\")\n",
    "\n",
    "    # Extract only samples of this attack class\n",
    "    real_data_class = df_train_attack[df_train_attack['attack_cat'] == attack_class][numerical_cols].values\n",
    "    real_data_class = torch.tensor(real_data_class, dtype=torch.float32)\n",
    "\n",
    "    # Generate synthetic samples after training the GAN\n",
    "    num_samples_needed = majority_class_size - len(real_data_class) # Calculate number of synthetic samples needed\n",
    "    noise = torch.randn(num_samples_needed, input_dim)\n",
    "    synthetic_samples = generator(noise).detach().numpy()\n",
    "\n",
    "    # Convert back to original scale\n",
    "    synthetic_samples = scaler.inverse_transform(synthetic_samples)\n",
    "\n",
    "    # Create DataFrame for the synthetic samples and label them with the same attack class\n",
    "    synthetic_df = pd.DataFrame(synthetic_samples, columns=numerical_cols)\n",
    "    synthetic_df['attack_cat'] = attack_class # Same name as the original attack class\n",
    "\n",
    "    # Store for merging later\n",
    "    synthetic_dataframes.append(synthetic_df)\n",
    "\n",
    "# Combine all synthetic data into one DataFrame\n",
    "final_synthetic_df = pd.concat(synthetic_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the synthetic data to a CSV file\n",
    "final_synthetic_df.to_csv('synthetic_attack_data.csv', index=False)\n",
    "print(\"Synthetic attack samples for all minority classes saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
